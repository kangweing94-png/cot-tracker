import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import datetime
import requests
import io
import time
import os
import math

# ========= å…¨å±€é…ç½® =========
st.set_page_config(page_title="Smart Money & Macro Pro", page_icon="ğŸ¦", layout="wide")

DATA_DIR = "data"
os.makedirs(DATA_DIR, exist_ok=True)

# ========= API KEYS =========
TE_API_KEY = "a7d624f316a049e:nmasw3jt5rkbeoi"          # TradingEconomicsï¼šåªåšçŠ¶æ€
FRED_API_KEY = "476ef255e486edb3fdbf71115caa2857"      # FRED å®˜æ–¹ APIï¼šä¸»å®è§‚æ•°æ®


# ========= ä¾§è¾¹æ  =========
with st.sidebar:
    st.header("âš¡ æ§åˆ¶å°")
    if st.button("ğŸ”„ åˆ·æ–°å…¨ç«™æ•°æ®"):
        st.cache_data.clear()
        st.rerun()

    st.divider()
    st.caption("æ•°æ®æº:\n- CFTC (COT)\n- FRED API (ä¸»å®è§‚)\n- TradingEconomics (çŠ¶æ€è¯Šæ–­)")


# ======================================================================
# æ¨¡å— 1: CFTC æ ¸å¿ƒé€»è¾‘ï¼ˆXAU / EUR / GBPï¼‰
# ======================================================================
@st.cache_data(ttl=3600 * 3)
def get_cftc_data():
    year = datetime.datetime.now().year
    url_history = f"https://www.cftc.gov/files/dea/history/fut_disagg_txt_{year}.zip"
    url_latest = "https://www.cftc.gov/dea/newcot/f_disagg.txt"

    headers = {"User-Agent": "Mozilla/5.0"}

    df_hist = pd.DataFrame()
    df_live = pd.DataFrame()

    # å†å²åŒ…
    try:
        r = requests.get(url_history, headers=headers, verify=False, timeout=10)
        if r.status_code == 200:
            df_hist = pd.read_csv(
                io.BytesIO(r.content), compression="zip", low_memory=False
            )
    except Exception:
        pass

    # æœ€æ–°ä¸€å‘¨
    try:
        r2 = requests.get(
            f"{url_latest}?t={int(time.time())}",
            headers=headers,
            verify=False,
            timeout=5,
        )
        if r2.status_code == 200 and not df_hist.empty:
            df_live = pd.read_csv(
                io.BytesIO(r2.content), header=None, low_memory=False
            )
            df_live.columns = df_hist.columns
    except Exception:
        pass

    if df_hist.empty and df_live.empty:
        return pd.DataFrame()

    return pd.concat([df_hist, df_live], ignore_index=True)


def find_column(columns, keywords):
    for col in columns:
        c = str(col).lower()
        if all(k in c for k in keywords):
            return col
    return None


def process_cftc(df, name_keywords):
    """
    ç­›é€‰èŠå•†æ‰€ä¸»åŠ›åˆçº¦ + è®¡ç®— Managed Money å‡€æŒä»“
    name_keywords é‡Œæ”¾çš„æ˜¯ä¸€ç»„ã€Œå¿…é¡»å…¨éƒ¨åŒ…å«çš„å…³é”®å­—ã€ï¼Œæ¯”å¦‚ï¼š
      - GOLD: ["GOLD", "COMMODITY"]
      - EUR:  ["EURO FX", "CHICAGO MERCANTILE"]
      - GBP:  ["BRITISH POUND STERLING", "CHICAGO MERCANTILE"]
    """
    if df.empty:
        return pd.DataFrame()

    # åˆçº¦åç§°åˆ—
    name_col = find_column(df.columns, ["market", "exchange"]) or find_column(
        df.columns, ["contract", "name"]
    )
    if not name_col:
        return pd.DataFrame()

    def _match_name(x):
        s = str(x).upper()
        return all(k.upper() in s for k in name_keywords)

    mask = df[name_col].apply(_match_name)
    data = df[mask].copy()
    if data.empty:
        return pd.DataFrame()

    # æ—¥æœŸåˆ—
    date_col = find_column(df.columns, ["report", "date"]) or find_column(
        df.columns, ["as", "of", "date"]
    )
    if not date_col:
        return pd.DataFrame()
    data[date_col] = pd.to_datetime(data[date_col], errors="coerce")
    data = data.dropna(subset=[date_col])

    # Managed Money å¤šç©ºåˆ—
    long_col = find_column(df.columns, ["money", "long"])
    short_col = find_column(df.columns, ["money", "short"])
    if not long_col or not short_col:
        return pd.DataFrame()

    data["Net"] = data[long_col] - data[short_col]
    data["Date_Display"] = data[date_col]

    data = data.sort_values("Date_Display")
    data = data.drop_duplicates(subset=["Date_Display"], keep="last")

    return data.tail(156)


# ======================================================================
# æ¨¡å— 2: FRED å®è§‚æ•°æ®ï¼ˆå®˜æ–¹ APIï¼‰+ TE çŠ¶æ€è¯Šæ–­
# ======================================================================

def _fred_api_series(series_id: str, start="1990-01-01"):
    """
    è°ƒç”¨ FRED å®˜æ–¹ APIï¼Œè¿”å› (series, status_text)
    æ³¨æ„ï¼šä¸å†ä¼  frequencyï¼Œé¿å… 400ã€‚
    """
    if not FRED_API_KEY:
        return None, "FRED: æ—  API Key"

    url = "https://api.stlouisfed.org/fred/series/observations"
    params = {
        "series_id": series_id,
        "api_key": FRED_API_KEY,
        "file_type": "json",
        "observation_start": start,
        "observation_end": "9999-12-31",
    }

    try:
        r = requests.get(url, params=params, timeout=10)
        if r.status_code != 200:
            return None, f"FRED {series_id} HTTP {r.status_code}"

        js = r.json()
        obs = js.get("observations", [])
        if not obs:
            return None, f"FRED {series_id} ç©ºç»“æœ"

        dates = []
        values = []
        for o in obs:
            d = o.get("date")
            v = o.get("value")
            if d is None or v is None:
                continue
            try:
                val = float(v)
                if math.isnan(val):
                    continue
            except ValueError:
                # '.' ç­‰ç¼ºå¤±å€¼
                continue
            dates.append(d)
            values.append(val)

        if not dates:
            return None, f"FRED {series_id} è§£æåæ— æœ‰æ•ˆæ•°æ®"

        df = pd.DataFrame({"DATE": pd.to_datetime(dates), "VALUE": values})
        df.set_index("DATE", inplace=True)
        df.sort_index(inplace=True)

        # ç®€å•å¤‡ä»½ä¸€ä»½
        backup_name = f"{series_id}.csv"
        df.to_csv(os.path.join(DATA_DIR, backup_name))

        return df["VALUE"], f"FRED {series_id} API æ­£å¸¸ ({len(df)} æ¡)"

    except Exception as e:
        # å°è¯•æœ¬åœ°å¤‡ä»½
        backup_name = f"{series_id}.csv"
        try:
            path = os.path.join(DATA_DIR, backup_name)
            df = pd.read_csv(path)
            df["DATE"] = pd.to_datetime(df["DATE"])
            df.set_index("DATE", inplace=True)
            df.sort_index(inplace=True)
            return df["VALUE"], f"FRED {series_id} æœ¬åœ°å¤‡ä»½ ({type(e).__name__})"
        except Exception:
            return None, f"FRED {series_id} å¤±è´¥: {type(e).__name__}"


def _te_status_only(country: str, indicator: str):
    if not TE_API_KEY:
        return "TE: æ—  API Key"

    url = f"https://api.tradingeconomics.com/historical/country/{country}/indicator/{indicator}"
    params = {"c": TE_API_KEY, "f": "json"}
    try:
        r = requests.get(url, params=params, timeout=5)
        return f"TE {indicator} HTTP {r.status_code}"
    except Exception as e:
        return f"TE {indicator} è¯·æ±‚å¤±è´¥: {type(e).__name__}"


@st.cache_data(ttl=3600 * 3)
def get_macro_from_fred():
    """
    çœŸæ­£ç”»å›¾/ç®—æŒ‡æ ‡ç”¨ FRED APIã€‚
    TE åªåšçŠ¶æ€è®°å½•ã€‚
    """
    sources = {}

    # Fed Funds
    fed, fed_info = _fred_api_series("FEDFUNDS", start="1980-01-01")
    te_fed = _te_status_only("united states", "interest rate")
    sources["fed_funds"] = f"{fed_info} | {te_fed}"

    # CPI YoY
    cpi_raw, cpi_info = _fred_api_series("CPIAUCSL", start="1980-01-01")
    if cpi_raw is not None:
        cpi_yoy = cpi_raw.pct_change(12) * 100
    else:
        cpi_yoy = None
    te_cpi = _te_status_only("united states", "inflation rate")
    sources["cpi_yoy"] = f"{cpi_info} | {te_cpi}"

    # NFP Change
    nfp_raw, nfp_info = _fred_api_series("PAYEMS", start="1980-01-01")
    if nfp_raw is not None:
        nfp_change = nfp_raw.diff()
    else:
        nfp_change = None
    te_nfp = _te_status_only("united states", "non farm payrolls")
    sources["nfp_change"] = f"{nfp_info} | {te_nfp}"

    # Jobless Claims
    claims_raw, claims_info = _fred_api_series("ICSA", start="1980-01-01")
    te_claims = _te_status_only("united states", "jobless claims")
    sources["jobless_claims"] = f"{claims_info} | {te_claims}"

    series_map = {
        "fed_funds": fed,
        "cpi_yoy": cpi_yoy,
        "nfp_change": nfp_change,
        "jobless_claims": claims_raw,
    }
    non_null = {k: v for k, v in series_map.items() if v is not None}
    if not non_null:
        return pd.DataFrame(), sources

    macro_df = pd.concat(non_null.values(), axis=1)
    macro_df.columns = list(non_null.keys())
    macro_df.sort_index(inplace=True)

    return macro_df, sources


# ======================================================================
# UI ç»„ä»¶
# ======================================================================
def render_cftc_alert(last_date):
    if pd.isnull(last_date):
        return
    diff = (datetime.datetime.now() - last_date).days
    if diff > 21:
        st.error(f"âš ï¸ CFTC æ•°æ®å·²æ»å {diff} å¤©ï¼ˆå¯èƒ½æ”¿åºœåœæ‘†æˆ–å®˜ç½‘ç»´æŠ¤ï¼‰")


def render_fomc_card():
    fomc_dates = [
        datetime.date(2025, 12, 10),
        datetime.date(2026, 1, 28),
        datetime.date(2026, 3, 18),
    ]
    today = datetime.date.today()
    next_meet = next((d for d in fomc_dates if d >= today), None)

    st.markdown("### ğŸ¦ FOMC è”é‚¦å…¬å¼€å¸‚åœºå§”å‘˜ä¼š")
    c1, c2 = st.columns([2, 1])
    with c1:
        if next_meet:
            days = (next_meet - today).days
            st.info(f"ğŸ“… ä¸‹æ¬¡åˆ©ç‡å†³è®®: **{next_meet}**ï¼ˆè¿˜å‰© {days} å¤©ï¼‰")
        else:
            st.info("ğŸ“… ä¸‹æ¬¡ä¼šè®®ï¼šå¾…å®š")
    with c2:
        st.link_button(
            "ğŸ“Š æŸ¥çœ‹æœ€æ–°ç‚¹é˜µå›¾",
            "https://www.federalreserve.gov/monetarypolicy/fomcprojtabl20250917.htm",
        )


def cot_chart(data, title, color):
    if data.empty:
        st.warning(f"{title}: æš‚æ— æ•°æ®ï¼ˆå¯èƒ½ CFTC åŸå§‹æ–‡ä»¶é‡Œåˆçº¦åä¸ä¸€è‡´ï¼‰")
        return

    last_row = data.iloc[-1]
    last_date = last_row["Date_Display"].strftime("%Y-%m-%d")
    net = int(last_row["Net"])

    st.metric(f"{title} Managed Money", f"{net:,}", f"æŠ¥å‘Šæ—¥æœŸ: {last_date}")

    fig = go.Figure()
    fig.add_trace(
        go.Scatter(
            x=data["Date_Display"],
            y=data["Net"],
            fill="tozeroy",
            line=dict(color=color),
            name="Net",
        )
    )
    fig.update_layout(
        height=300,
        margin=dict(t=10, b=0, l=0, r=0),
        xaxis_title="Report Date",
        yaxis_title="Net Position",
    )
    st.plotly_chart(fig, use_container_width=True)


# ======================================================================
# ä¸»ç¨‹åº
# ======================================================================
with st.spinner("æ­£åœ¨åŒæ­¥ COT & å®è§‚æ•°æ®â€¦"):
    # CFTC
    cftc_df = get_cftc_data()
    xau_data = process_cftc(cftc_df, ["GOLD", "COMMODITY"])
    eur_data = process_cftc(cftc_df, ["EURO FX", "CHICAGO MERCANTILE"])
    gbp_data = process_cftc(cftc_df, ["BRITISH POUND STERLING", "CHICAGO MERCANTILE"])

    # å®è§‚ï¼šFRED API ä¸ºä¸»ï¼ŒTE åªåšçŠ¶æ€
    macro_df, macro_sources = get_macro_from_fred()

st.title("Smart Money & Macro Dashboard")

# CFTC é¡¶éƒ¨è­¦æŠ¥
if not xau_data.empty:
    render_cftc_alert(xau_data.iloc[-1]["Date_Display"])

tab1, tab2 = st.tabs(["ğŸ“Š COT æŒä»“ï¼ˆEUR / GBP / XAUï¼‰", "ğŸŒ å®è§‚ç»æµï¼ˆFRED API + TE çŠ¶æ€ï¼‰"])


# ---------- Tab1: COT ----------
with tab1:
    # ä¸Šæ’ï¼šEUR + GBP
    c1, c2 = st.columns(2)
    with c1:
        st.subheader("Euro (EUR) æœŸè´§ - Managed Money å‡€æŒä»“")
        cot_chart(eur_data, "Euro (EUR)", "#00d2ff")
    with c2:
        st.subheader("British Pound (GBP) æœŸè´§ - Managed Money å‡€æŒä»“")
        cot_chart(gbp_data, "British Pound (GBP)", "#ff7f0e")

    st.subheader("Gold (XAU) æœŸè´§ - Managed Money å‡€æŒä»“")
    cot_chart(xau_data, "Gold (XAU)", "#FFD700")


# ---------- Tab2: å®è§‚ ----------
with tab2:
    render_fomc_card()
    st.divider()

    st.subheader("ğŸ“Œ å®è§‚æ•°æ®æ¥æºï¼ˆFRED ä¸» + TE çŠ¶æ€ï¼‰")
    st.json(macro_sources)

    if macro_df.empty:
        st.warning("FRED API ä¹Ÿæ‹‰ä¸åˆ°æ•°æ®ï¼ˆç½‘ç»œ/é˜²ç«å¢™é—®é¢˜ï¼‰ï¼Œå®è§‚åŒºæš‚æ—¶ç©ºç™½ã€‚")
    else:
        latest = macro_df.dropna().iloc[-1]

        m1, m2, m3, m4 = st.columns(4)

        if "fed_funds" in macro_df.columns and pd.notna(latest.get("fed_funds", None)):
            m1.metric("ğŸ‡ºğŸ‡¸ Fed Funds Rate", f"{latest['fed_funds']:.2f}%")
        else:
            m1.write("Fed Funds: æ— æ•°æ®")

        if "cpi_yoy" in macro_df.columns and pd.notna(latest.get("cpi_yoy", None)):
            m2.metric("ğŸ”¥ CPI (YoY)", f"{latest['cpi_yoy']:.1f}%")
        else:
            m2.write("CPI YoY: æ— æ•°æ®")

        if "nfp_change" in macro_df.columns and pd.notna(latest.get("nfp_change", None)):
            m3.metric("ğŸ‘· NFP Change", f"{int(latest['nfp_change']):,}")
        else:
            m3.write("NFP Change: æ— æ•°æ®")

        if "jobless_claims" in macro_df.columns and pd.notna(
            latest.get("jobless_claims", None)
        ):
            m4.metric("ğŸ¤• Jobless Claims", f"{int(latest['jobless_claims']):,}")
        else:
            m4.write("Jobless Claims: æ— æ•°æ®")

        st.divider()

        c1, c2 = st.columns(2)
        with c1:
            st.subheader("é€šèƒ€è¶‹åŠ¿ (CPI YoY)")
            if "cpi_yoy" in macro_df.columns and macro_df["cpi_yoy"].notna().sum() > 0:
                st.line_chart(macro_df["cpi_yoy"].tail(60))
            else:
                st.info("æš‚æ—  CPI YoY æ•°æ®")

        with c2:
            st.subheader("å°±ä¸šå¸‚åœº - éå†œå˜åŒ– (NFP Change)")
            if "nfp_change" in macro_df.columns and macro_df["nfp_change"].notna().sum() > 0:
                st.bar_chart(macro_df["nfp_change"].tail(60))
            else:
                st.info("æš‚æ—  NFP Change æ•°æ®")

        st.subheader("åˆè¯·å¤±ä¸šé‡‘ (Jobless Claims)")
        if "jobless_claims" in macro_df.columns and macro_df["jobless_claims"].notna().sum() > 0:
            st.line_chart(macro_df["jobless_claims"].tail(60))
        else:
            st.info("æš‚æ—  Jobless Claims æ•°æ®")
